{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d8129f9",
   "metadata": {},
   "source": [
    "# Classic pre-prediction processing tools\n",
    "\n",
    "Howdy there you handsome Hacker! Fancy seeing you here (ah-wink-ah-wink, if ya'll know what I'm saying) - I am not drunk writing this, I'm just listening to southern folk music.\n",
    "\n",
    "Aaaanyways, this notebook is made specifically for you to have a nice, all-in-one collection of functions that can be useful for your pre-processing of pdb files, or any other types of input files that you may need for running predictions on your favourite model.\n",
    "\n",
    "Here you will find :\n",
    "\n",
    "- convert your file from pdb to cif\n",
    "- convert yoour file from cif to pdb\n",
    "- convert files from pdb to FASTA for AF3 prediction from server\n",
    "\n",
    "**N.B.** : For the following pipelines you will need to download **BioPython** and **Biotite** from your terminal. We reccommend you do this in a **Python Virtual Environment (venv)**. If you're a Newbie to venv, you can ask your favourite AI agent how to create one on your PC :) .\n",
    "\n",
    "If you're using python, after avtivating your venv, run:\n",
    "\n",
    "-       pip install --upgrade pip\n",
    "-       pip install biopython\n",
    "-       pip install biotite\n",
    "\n",
    "If you're on macbook (bash-zsh) run:\n",
    "\n",
    "-       brew install biopython\n",
    "-       brew install biotite\n",
    "\n",
    "If any other needs for pre-processing come to your attention, please report to one of the coaches, and we'll make sure to add some code for that as well!\n",
    "\n",
    "In the meantime, just enjoy the process, and happy protein engineering!\n",
    "\n",
    "See ya mate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caf9164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 1. Import all the libraries you need\n",
    "# ======================================================\n",
    "#!/usr/bin/env python\n",
    "#!/usr/bin/env python\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from Bio.PDB.MMCIFParser import MMCIFParser\n",
    "from Bio.PDB import PDBIO\n",
    "from Bio import SeqIO\n",
    "import biotite.structure.io.pdb as pdb\n",
    "import biotite.structure.io.pdbx as pdbx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498ab160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 1. Convert CIF files to PDB format\n",
    "# ======================================================\n",
    "\n",
    "def rename_chains(structure):\n",
    "    \"\"\"Rename chains to single-letter IDs for PDB compatibility.\"\"\"\n",
    "    chainmap = {c.id: c.id for c in structure.get_chains() if len(c.id) == 1}\n",
    "    next_chain = 0\n",
    "    for chain in structure.get_chains():\n",
    "        if len(chain.id) != 1:\n",
    "            if chain.id[0] not in chainmap:\n",
    "                chainmap[chain.id[0]] = chain.id\n",
    "                chain.id = chain.id[0]\n",
    "            else:\n",
    "                while True:\n",
    "                    c = chr(ord('A') + (next_chain % 26)) if next_chain < 26 else \\\n",
    "                        str(next_chain - 26) if next_chain < 36 else \\\n",
    "                        chr(ord('a') + next_chain - 36)\n",
    "                    next_chain += 1\n",
    "                    if c not in chainmap:\n",
    "                        chainmap[c] = chain.id\n",
    "                        chain.id = c\n",
    "                        break\n",
    "    return chainmap\n",
    "\n",
    "cif_pattern = \"/your/cif/folder/*.cif\"  # Update to your glob pattern\n",
    "cif_files = glob.glob(cif_pattern)\n",
    "\n",
    "for ciffile in cif_files:\n",
    "    try:\n",
    "        strucid = os.path.basename(ciffile)[:4]\n",
    "        parser = MMCIFParser()\n",
    "        structure = parser.get_structure(strucid, ciffile)\n",
    "        rename_chains(structure)\n",
    "        \n",
    "        # New saving logic: create subfolder and compute output path\n",
    "        cif_dir = Path(ciffile).parent\n",
    "        output_dir = cif_dir / \"converted_pdbs\"\n",
    "        output_dir.mkdir(exist_ok=True)  # Creates if missing\n",
    "        pdb_filename = Path(ciffile).stem + \".pdb\"\n",
    "        pdbfile = output_dir / pdb_filename\n",
    "        \n",
    "        io = PDBIO()\n",
    "        io.set_structure(structure)\n",
    "        io.save(str(pdbfile))  # Use str() for Path compatibility\n",
    "        print(f\"Success: {ciffile} -> {pdbfile}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error with {ciffile}: {e}\")\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 2. Convert PDB files to CIF format\n",
    "# ======================================================\n",
    "\n",
    "# === SET YOUR PATHS HERE ===\n",
    "input_folder = \"/your/input/path\"  # Change this\n",
    "output_folder = \"/your/output/folder\"  # Change this\n",
    "\n",
    "def convert_pdb_to_cif(input_folder: str, output_folder: str):\n",
    "    input_path = Path(input_folder)\n",
    "    output_path = Path(output_folder)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    pdb_files = list(input_path.glob(\"*.pdb\")) + list(input_path.glob(\"*.PDB\"))\n",
    "    print(f\"Found {len(pdb_files)} PDB files to convert\")\n",
    "    \n",
    "    for pdb_file_path in pdb_files:\n",
    "        pdb_filename = pdb_file_path.stem\n",
    "        output_cif_path = output_path / f\"{pdb_filename}.cif\"\n",
    "        \n",
    "        try:\n",
    "            # FIXED: Skip bonds + explicit extra_fields to avoid parsing occupancy/b-factor\n",
    "            pdb_file = pdb.PDBFile.read(pdb_file_path)\n",
    "            structure = pdb_file.get_structure(\n",
    "                model=1, \n",
    "                include_bonds=False,  # Skip bond inference (causes field parsing)\n",
    "                extra_fields=[]       # Skip optional fields that trigger strict parsing\n",
    "            )\n",
    "            \n",
    "            # Write as CIF\n",
    "            cif_file = pdbx.CIFFile()\n",
    "            pdbx.set_structure(cif_file, structure)\n",
    "            cif_file.write(output_cif_path)\n",
    "            \n",
    "            print(f\"✓ {pdb_filename}.pdb → {output_cif_path.name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"✗ Failed {pdb_filename}: {str(e)[:80]}...\")\n",
    "\n",
    "# RUN CONVERSION\n",
    "convert_pdb_to_cif(input_folder, output_folder)\n",
    "print(\"Batch conversion complete!\")\n",
    "\n",
    "# ======================================================\n",
    "# 3. Convert PDB files to FASTA format - useful for AF3\n",
    "# ======================================================\n",
    "# This lines are for the same purpose but in batch\n",
    "def batch_structures_to_fasta(input_dir: str | Path,\n",
    "                              output_dir: str | Path,\n",
    "                              single_output: bool = False):\n",
    "    input_dir = Path(input_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if single_output:\n",
    "        merged_path = output_dir / \"all_sequences.fasta\"\n",
    "        if merged_path.exists():\n",
    "            merged_path.unlink()\n",
    "\n",
    "    total_chains = 0\n",
    "    for path in input_dir.iterdir():\n",
    "        if path.suffix.lower() != \".pdb\":  # Adjust if you have CIFs\n",
    "            continue\n",
    "\n",
    "        records = list(SeqIO.parse(str(path), \"pdb-atom\"))\n",
    "        if not records:\n",
    "            print(f\"Skipped {path.name}: no ATOM records\")\n",
    "            continue\n",
    "\n",
    "        total_chains += len(records)\n",
    "        if single_output:\n",
    "            for rec in records:\n",
    "                rec.id = f\"{path.stem}|{rec.id}\"\n",
    "                rec.description = \"\"\n",
    "            with open(merged_path, \"a\") as handle:\n",
    "                SeqIO.write(records, handle, \"fasta\")\n",
    "        else:\n",
    "            out_path = output_dir / f\"{path.stem}.fasta\"\n",
    "            SeqIO.write(records, str(out_path), \"fasta\")\n",
    "\n",
    "    print(f\"Processed {total_chains} total chains\")\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Example usage:\n",
    "# ---------------------------\n",
    "\n",
    "batch_structures_to_fasta(\"PDBspath\", \"FASTAspath\", single_output=False)\n",
    "# or:\n",
    "batch_structures_to_fasta(\"PDBspath\", \"FASTAspath\", single_output=True) \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
